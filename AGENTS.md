# Repository Agent Notes

## Purpose
This repository powers the ebook-tools platform, bundling a FastAPI backend, background job helpers, and a Vite/React frontend for rendering and managing multimedia ebook assets.

## Key Entry Points
- **Backend:** `modules/webapi/application.py` exposes the FastAPI app factory referenced by `python -m modules.webapi` and the `ebook-tools-api` console script.
- **CLI / Orchestration:** `ebook-tools.py` and `scripts/` house helper commands for running pipelines locally.
- **Frontend:** `web/` contains the Vite application. Source files live under `web/src/`, while built assets default to `web/dist/`.
- **Offline exports:** `modules/services/export_service.py` builds offline player bundles for completed jobs/library entries via `/api/exports`, using the export player entry at `web/export.html` + `web/src/export-player/` (built with `vite build --mode export` into `web/export-dist`, override via `EBOOK_EXPORT_PLAYER_ROOT`). Export archives land under `storage/exports` (override via `EBOOK_EXPORT_ROOT`).
- **Apple Clients:** `ios/InteractiveReader/` now ships iOS/iPadOS + tvOS targets that authenticate via `/api/auth/login`, list Library entries from `/api/library/items`, and play library media via `/api/library/media/{job_id}` plus `/api/jobs/{job_id}/timing`. Shared SwiftUI flows live under `Features/Auth`, `Features/Library`, and `Features/Playback`, with the tvOS target configured through `InteractiveReader/Supporting/Info-tvOS.plist`.
- **Frontend Book Flows:** `web/src/pages/NewImmersiveBookPage.tsx` unifies the submission and settings experience behind the sidebar entry “Narrate Ebook,” sharing language state with `web/src/pages/CreateBookPage.tsx` and `web/src/components/book-narration/BookNarrationForm.tsx` via `web/src/context/LanguageProvider.tsx`. `CreateBookPage` now submits a managed `book` job via `/api/books/jobs`, first generating a seed EPUB with the LLM and then running the standard pipeline with the same Narrate Ebook form settings.
- **Search:** `modules/webapi/routes.py` exposes `/api/pipelines/search`, which now requires a `job_id` query parameter, scans that job's persisted chunks for snippets surfaced in the frontend `MediaSearchPanel`, and falls back to library metadata when the pipeline job has already been archived.
- **Audio Voices:** `modules/webapi/routers/audio.py` serves `/api/audio/voices` for language-specific voice inventories and `/api/audio` for preview synthesis consumed by the `BookNarrationForm` voice picker.
- **Library:** `modules/library/` now splits the domain into `library_models`, `library_repository`, `library_metadata`, `library_sync`, and the lightweight `library_service` facade consumed by `modules/webapi/routers/library.py`; the frontend experience lives in `web/src/pages/LibraryPage.tsx` and related components.
- **Library video items:** Library entries track an `item_type` (`book` or `video`); completed YouTube dubbing jobs (`youtube_dub`) can be moved into the Library NAS for playback alongside books.
- **Metadata Storage:** `storage/<job_id>/metadata/` now persists a compact `job.json` manifest (with `chunk_manifest` summaries) plus per-chunk JSON files (`chunk_0000.json`, `chunk_0001.json`, …) for highlight timelines. Use `MetadataLoader` in `modules/metadata_manager.py` to read either the new chunked format or legacy single-file payloads.
- **Content Index:** `storage/<job_id>/metadata/content_index.json` stores chapter ranges (title + sentence boundaries + alignment status). `book_metadata` includes `content_index_path` / `content_index_url` pointers so downstream tools can fetch it for chapter navigation or LLM analysis.
- **Sentence Images:** `modules/images/` provides the Draw Things / Stable Diffusion client (`drawthings.py`) and prompt helpers (`prompting.py`). `modules/core/rendering/pipeline.py` runs image generation in parallel with translation when `add_images` is enabled, storing PNGs under `media/images/<range_fragment>/sentence_XXXXX.png` and writing paths/prompts into chunk metadata. The web API exposes inspection/regeneration endpoints in `modules/webapi/routes/media_routes.py`, and the frontend consumes them via the image reel in `web/src/components/InteractiveTextViewer.tsx` plus the `MyPainter` UI (`web/src/components/MyPainterAssistant.tsx`).
- **Subtitles:** Subtitle parsing/rendering now lives in `modules/subtitles/` (I/O + language helpers + merging + rendering + translation utilities) with `modules/subtitles/processing.py` orchestrating colourised output. Supports per-word SRT highlighting, optional ASS exports, configurable start/end time windows (including relative offsets), and the `original_language`/`show_original` options exposed on `SubtitleToolPage.tsx` via `modules/webapi/routers/subtitles.py`.
- **YouTube NAS dubbing:** `modules/services/youtube_dubbing/` splits NAS discovery, subtitle extraction, dubbing generation, and service orchestration; it lists downloaded videos under `/Volumes/Data/Download/DStation` and builds dubbed audio tracks from adjacent ASS subtitles. `/api/subtitles/youtube/dub` enqueues `youtube_dub` jobs (tracked alongside pipelines/subtitles) via `YoutubeDubbingService`, and the frontend entry `web/src/pages/VideoDubbingPage.tsx` lists NAS videos plus active dubbing jobs.
- **Alignment:** `modules/align/backends/whisperx_adapter.py` shells out to the WhisperX CLI when `forced_alignment_enabled` and `alignment_backend` are configured, allowing `modules/render/audio_pipeline.py` to pull real word tokens whenever the TTS backend omits them. The pipeline now auto-selects the WhisperX model per target language (honouring `alignment_model_overrides` when provided) and logs the choice so drift investigations stay transparent. Set `EBOOK_HIGHLIGHT_POLICY=forced` to fail jobs that would otherwise fall back to inferred timings.
- **Timing Policies:** Use `char_weighted_highlighting_default=true` (or `EBOOK_CHAR_WEIGHTED_HIGHLIGHTING_DEFAULT=1`) to prefer character-weighted timings and pair it with `char_weighted_punctuation_boost=true` (`EBOOK_CHAR_WEIGHTED_PUNCTUATION_BOOST=1`) when you want punctuation-aware pacing before the renderer falls back to uniform inference.

## Audio, Metadata & Highlighting Cheat Sheet
- **Audio generation.** `modules/render/audio_pipeline.py` streams translation tasks into the active backend from `modules/audio/backends/`. Each sentence now yields separate `orig` and `translation` audio tracks (no concatenated mix), and the worker records provenance for both via `highlighting_summary` (translation) plus `original_highlighting_summary` (original), covering backend tokens, WhisperX (`modules/align/backends/whisperx_adapter.py`), char-weighted inference, or uniform fallbacks.
- **Metadata creation.** `modules/services/job_manager/persistence.py` writes `metadata/job.json`, `metadata/chunk_manifest.json`, and per-chunk files (`metadata/chunk_XXXX.json`). Chunks now carry `audioTracks.orig` + `audioTracks.translation` and `timingTracks.original` + `timingTracks.translation` (legacy `orig_trans`/`mix` only for older jobs). `MetadataLoader` in `modules/metadata_manager.py` can load both the chunked format and the legacy single-file payload, so always run metadata reads through it to stay forward-compatible.
- **Highlighting controls.** `EBOOK_HIGHLIGHT_POLICY` decides whether a job may fall back to inferred timings, while `char_weighted_highlighting_default`/`char_weighted_punctuation_boost` (or their env vars) tune character-weighted inference. Each chunk now records a `highlighting_policy` summary (per-token `policy`/`source` are no longer persisted); legacy jobs still surface policy via `/api/jobs/{job_id}/timing`.
- **Sentence images.** When `add_images` is enabled, the renderer calls a Draw Things / Stable Diffusion `txt2img` endpoint (`image_api_base_url` or clustered `image_api_base_urls`) in parallel worker threads (`image_concurrency`, default 4), balancing work by node availability so faster nodes naturally handle more. Each generated image is stored under `storage/jobs/<job_id>/media/images/<range_fragment>/sentence_XXXXX.png` and referenced from `metadata/chunk_XXXX.json` as `sentences[].image` (plus `image_path` / `imagePath`). Use `docs/sentence_images.md` as the reference for prompt/style rules and regeneration endpoints.
- **ASS word highlights.** Subtitle exports pace highlights per word (character-weighted with a light uniform blend) across the subtitle span, cap preroll at 0.35s, and drop tail padding to avoid overlaps; YouTube dubbing ignores noisy speech windows and trusts the dubbed subtitle duration so karaoke timing stays smooth even when silence detection jitters.
- **Update expectation.** Whenever the audio stack, metadata layout, or highlighting logic changes, update these bullets plus the relevant docs (`README.md`, `docs/sentence_highlighting.md`, `docs/interactive_reader_metadata.md`) so downstream agents do not need to reverse-engineer the current behaviour.
  When sentence-image generation or playback UX changes, update `docs/sentence_images.md` and `docs/frontend-sync.md` as well.

## Common Workflows
- Create a virtual environment and install dependencies with `pip install -e .[dev]`.
- Start the API for local development with `uvicorn modules.webapi.application:create_app --factory --reload`.
- `scripts/run-webapi.sh` starts a second HTTP listener for Apple TV on port 8001 by default; set `EBOOK_API_TV_HTTP_PORT=0` (optional `EBOOK_API_TV_HTTP_HOST`) to disable or override.
- Run the test suite via `pytest` from the repository root.
- Library storage defaults to `/Volumes/Data/Video/Library`; override via `library_root` in `config/config.local.json` or the `LIBRARY_ROOT` environment variable when running services locally.

## Style Reminders
- Prefer explicit imports and keep module-level side effects minimal.
- Align with the FastAPI conventions already present: Pydantic models in `modules/webapi/schemas/`, services under `modules/services/`, and routers under `modules/webapi/`.
- Frontend components follow a co-located CSS Modules pattern (`Component.tsx` with `Component.module.css`).

## Updating These Notes
Whenever a task introduces new subsystems, moves files, or changes the recommended commands, add or adjust the relevant sections above so future agents land with accurate context.
